{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import re\n",
    "from scipy.stats import pmean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxonomic_levels = {\"d\": 0, \"p\": 1, \"c\": 2, \"o\": 3, \"f\": 4, \"g\": 5, \"s\": 6}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_index(df: pd.DataFrame, index_col: int) -> pd.DataFrame:\n",
    "    if index_col == 0:\n",
    "        df.set_index(df.columns[0], inplace=True)\n",
    "        df.drop(columns=['even_stag', 'run', 'in_out', 'v_region'], inplace=True)\n",
    "        return df\n",
    "\n",
    "    else:\n",
    "        df = df.iloc[:, index_col:]\n",
    "        df.set_index(df.columns[0], inplace=True)\n",
    "        return df\n",
    "\n",
    "def determine_taxonomic_rank(split_classification: list, taxon_level: str) -> str:\n",
    "    if len(split_classification) == taxonomic_levels[taxon_level]+1:\n",
    "        return split_classification[-1]\n",
    "    else:\n",
    "        return \"Assigned_Higher\"\n",
    "    \n",
    "def clean_columns(df: pd.DataFrame, delimiter_pattern=\";\", transpose=False, taxon_level=\"g\"):\n",
    "    new_labels = []\n",
    "    data = []\n",
    "    if transpose:\n",
    "        data = df.columns.to_list()\n",
    "    else:\n",
    "        data = df.index.to_list()\n",
    "\n",
    "    for c in data:\n",
    "        print(c)\n",
    "        pattern1 = re.compile(delimiter_pattern)\n",
    "        col6 = re.split(pattern1, c)\n",
    "        print(col6)\n",
    "\n",
    "        org_name = determine_taxonomic_rank(col6, taxon_level)\n",
    "\n",
    "        # pattern2 = re.compile(r'')\n",
    "        # col6_clean = re.split(pattern2, col6)[-1]\n",
    "\n",
    "        if org_name == '__' or org_name == f'{taxon_level}__':\n",
    "            new_labels.append(\"Assigned_Higher\")\n",
    "            continue\n",
    "\n",
    "        new_labels.append(org_name)\n",
    "\n",
    "    # print(new_cols)\n",
    "    if transpose:\n",
    "        df.columns = new_labels\n",
    "        display(df.head())\n",
    "        return df \n",
    "    else:\n",
    "        df.index = new_labels\n",
    "        display(df.head())\n",
    "        return df\n",
    "\n",
    "\n",
    "def clean_csv(root, f, delimiter_pattern=\";\", transpose=False, index_col=0, taxon_level=\"g\"):\n",
    "    print(f)\n",
    "    df = pd.read_csv(os.path.join(root, f))\n",
    "    # display(df)\n",
    "\n",
    "    df = fix_index(df, index_col)\n",
    "    display(df.head())\n",
    "\n",
    "    clean_columns(df, delimiter_pattern, transpose, taxon_level)\n",
    "\n",
    "    if transpose:\n",
    "        deduped = df.groupby(lambda x:x, axis=1).sum()\n",
    "        return deduped.T\n",
    "\n",
    "    else:\n",
    "        deduped = df.groupby(lambda x:x, axis=0).sum()\n",
    "        return deduped\n",
    "        \n",
    "cleaned_df = []\n",
    "\n",
    "silva_dir = '/Volumes/TBHD/Bioinformatics/ion_torrent_qiime2_methods_manuscript/Classified_Tax_Counts_QIIME2_CSV_Files/Cutprimers/Species'\n",
    "set_2_dir = '/Volumes/TBHD_share/multi_v_regions_tables/FirstTestSet_stool/data'\n",
    "\n",
    "for root, dirs, file in os.walk(set_2_dir):\n",
    "    for f in file:\n",
    "        # if \"Silva\" in f:\n",
    "        cleaned_df.append(clean_csv(root, f, delimiter_pattern=\",\", transpose=False, index_col=1, taxon_level=\"g\"))\n",
    "        # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extra_column_cleaning(df):\n",
    "    cols = df.columns.to_list()\n",
    "    new_cols = []\n",
    "    for c in cols:\n",
    "        pattern = re.compile(r'_V\\d')\n",
    "        splitted = re.split(pattern, c)\n",
    "        new_cols.append(splitted[0])\n",
    "\n",
    "    df.columns = new_cols\n",
    "    return df\n",
    "\n",
    "extra_clean = [extra_column_cleaning(df) for df in cleaned_df]\n",
    "# df1 = extra_clean[0].iloc[0:5, 0:8]\n",
    "# display(df1.head())\n",
    "# df2 = extra_clean[1].iloc[0:5, 0:8]\n",
    "# df3 = extra_clean[2].iloc[0:5, 0:8]\n",
    "\n",
    "# print(df1.shape)\n",
    "# print(df2.shape)\n",
    "# print(len(extra_clean))\n",
    "out = pd.concat(extra_clean, axis=0)\n",
    "# display(out)\n",
    "\n",
    "groups = out.groupby(level=0, axis=0)\n",
    "c = 0\n",
    "\n",
    "final = pd.DataFrame()\n",
    "for g in groups:\n",
    "    # print(g[0])\n",
    "    # display(g[1])\n",
    "    m = pd.DataFrame(pmean(g[1], axis=0, p=2, nan_policy='omit')).T\n",
    "    m.columns = g[1].columns\n",
    "    m.index = [g[0]]\n",
    "\n",
    "    final = pd.concat([final, m], axis=0)\n",
    "\n",
    "    # display(m)\n",
    "    # c+=1\n",
    "    # if c == 10:\n",
    "        # break\n",
    "\n",
    "display(final.head())\n",
    "final.to_csv(\"final.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "14bc8cabf365ccf5e373e54aa5ed33141be8fb7ea435d28f3fb87f439a44db21"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
